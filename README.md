# learn-kafka

> 아파치 카프카 애플케이션 프로그래밍 with 자바를 읽고 정리 및 실습을 위한 repo


## 1장. 들어가며

### 로그 (모든 소프트웨어 엔지니어가 실시간 데이터의 통합 추상화에 대해 알아야 할 사항)
- https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying



# 3장. 카프카 기본 개념 설명

## 3.1 카프카 브로커, 클러스터, 주키퍼

### **카프카 브로커란?**
> 카프카 클라이언트와 데이터를 주고 받기 위해 사용하는 주체이자, 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 애플리케이션이다.

- 하나의 서버에는 한 개의 카프카 브로커 프로세스가 실행된다.
- 카프카 브로커 서버 1대로도 기본 기능이 실행되지만, 데이터를 안전하게 보관하고 처리하 위해 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영한다.
- 카프카 클러스터로 묶인 브로커들은 프로듀서가 보낸 데이터를 안전하게 분산 저장하고 복제하는 역할을 수행한다.

#### 데이터 저장과 전송 

- 카프카는 데이터 저장을 위해 파일 시스템을 사용하고 파일 시스템의 읽기 성능을 위해 페이지 캐시(page cache)를 사용하여 디스크 입출력 속도를 높였다.
  - 페이지 캐시란 OS 에서 파일 입출력의 성능 향상을 위해 만들어 놓은 메모리 영역을 뜻함
  - 한번 읽은 파일의 내용은 메모리의 페이지 캐시 영역에 저장

#### 데이터 복제와 싱크

- 카프카의 데이터 복제는 파티션 단위로 이루어지며, 토픽을 생성할 때 파티션의 복제 개수도 같이 설정한다.
- 복제된 파티션은 리더와 팔로워로 구성되고 프로듀서 또는 컨슈머와 직접 통신하는 파티션을 리더, 나머지 복제 데이터를 가지고 있는 파티션을 팔로워라 한다.

#### 컨트롤러
- 클러스터의 다수 브로커 중 한 대가 컨트롤러의 역할을 한다. 컨트롤러는 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배 한다.

#### 데이터 삭제
- 카프카는 다른 메시징 플랫폼과 다르게 컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않는다.
  - 컨슈머나 프로듀서가 데이터 삭제를 요청할 수도 없다.
  - 오직 브로커만이 데이터를 삭제할 수 있다.
- 데이터 삭제는 파일 단위로 이루어지는데 <b>로그 세그먼트</b>라 부른다.

#### 컨슈머 오프셋 저장

- 컨슈머 그룹은 파티션의 어느 레코드까지 가져갔는지 확인을 위해 오프셋을 커밋한다. (__consumer_offsets 토픽에 저장)
- 저장된 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 가져가서 처리한다.

#### 코디네이터(coordinator)

>클러스터의 다수 브로커 중 한 대는 코디네이터의 역항을 수행한다.
- 코디네이터는 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할을 한다.
- 컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 동작하는 커슈머로 할당하여 끊임없이 데이터가 처리 되도록(일을 하도록) 도와준다.
  - 이러한 과정을 <b>리밸런스(Rebalance)</b>라 부른다.

<hr>

### **주키퍼란?**

> 주키퍼는 카프카의 메타데이터를 관리하는 데에 사용된다.
> [주키퍼 쉘 명령어](https://zookeeper.apache.org/doc/current/zookeeperStarted.html)

- 카프카 클러스터로 묶인 브로커들은 동일한 경로의 주커퍼 경로로 선언해야 같은 카프카 브로커 묶임이 된다.
- 클러스터를 여러 개로 운영한다면 한 개의 주키퍼에 다수의 카프카 클러스터를 연결해서 사용할 수도 있다.

#### znode

- 주키퍼에서 사용하는 데이터 저장 단위이다.
- 파일 시스템처럼 znode간에 계층 구조를 가진다.
  - 1개의 znode는 n개의 하위 znode가 존재하고 계속해서 tree 구조로 znode가 존재할 수 있다.
- 2개 이상의 카프카 클러스터를 구축할 때는 root znode가 아닌 한 단계 아래의 znode를 카프카 브로커 옵션으로 지정해야 한다.
  - 파이프라인 : zookeeper.connect=localhost:2181/pipeline 
  - 실시간 추천 시스템 : zookeeper.connect=localhost:2181/recommend
  
<hr>

## 3.2 토픽과 파티션

### **토픽**

> 토픽은 카프카에서 데이터를 구분하기 위해 사용하는 단위이다. 토픽은 1개 이상의 파티션을 소유하고 있다.

#### 의미있는 토픽 이름
토픽의 이름은 데이터의 얼굴이다. 최소한 토픽 이름을 통해 어떤 개발환경에서 사용되는 것인지 판단 가능해야 하고 어떤 애플리케이션에서 어떤 데이터 타입인지 유추할 수 있어야 한다.

kebab-case나 snake_case가 권장되며 특수문자를 조합하여 사용하면 좋다.

##### 예시)
- <환경>.<팀-명>.<애플리케이션-명>.<메시지-타입>
  - dev.marketing-team.sms-platform.json
- <프로젝트-명>.<서비스-명>.<환경>.<이벤트-명>
  - commerce.payment.dev.notification
- <환경>.<서비스-명>.<JIRA-번호>.<메시지-타입>
  - dev.email-sender.jira-1234.email-vo-custom
- <카프카-클러스터-명>.<환경>.<서비스-명>.<메시지-타입>
  - aws-kafka.live.marketing-platform.json

<hr>

### **파티션**

> 파티션에는 프로듀서가 보낸 데이터들이 들어가 저장되는데 이 데이터를 레코드(record) 라고 부른다.

- 파티션은 자료구조에서 접하는 큐와 비슷한 구조이지만, 데이터를 가져가더라도 레코드를 삭제하지 않는다.
  - 이 특징으로 인해 토픽의 레코드는 다양한 목적을 가진 여러 컨슈머 그룹들이 토픽의 데이터를 여러 번 가져갈 수 있다.
- 파티션은 카프카의 병렬처리의 핵심으로써 컨슈머 그룹이 레코드를 병렬로 처리할 수 있도록 매칭된다.
